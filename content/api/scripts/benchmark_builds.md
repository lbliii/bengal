
---
title: "benchmark_builds"
type: "python-module"
source_file: "bengal/scripts/benchmark_builds.py"
line_number: 1
description: "Benchmark different Bengal build modes for cold builds. Compares: 1. Standard build (parallel) 2. Standard build (sequential / --no-parallel) 3. Pipeline build (--pipeline) 4. Fast mode (--fast) Each ..."
---

# benchmark_builds
**Type:** Module
**Source:** [View source](bengal/scripts/benchmark_builds.py#L1)



**Navigation:**
[scripts](/api/scripts/) â€ºbenchmark_builds

Benchmark different Bengal build modes for cold builds.

Compares:
1. Standard build (parallel)
2. Standard build (sequential / --no-parallel)
3. Pipeline build (--pipeline)
4. Fast mode (--fast)

Each run:
- Cleans cache completely (ensures cold build)
- Times the build
- Captures key metrics

## Classes




### `BuildResult`


Result of a single build run.


:::{info}
This is a dataclass.
:::



**Attributes:**

| Name | Type | Description |
|:-----|:-----|:------------|
| `name` | - | *No description provided.* |
| `command` | - | *No description provided.* |
| `elapsed_seconds` | - | *No description provided.* |
| `exit_code` | - | *No description provided.* |
| `success` | - | *No description provided.* |
| `pages_rendered` | - | *No description provided.* |
| `output_lines` | - | *No description provided.* |
| `error_output` | - | *No description provided.* |







## Methods



#### `__str__`
```python
def __str__(self) -> str
```


*No description provided.*



**Returns**


`str`

## Functions



### `clean_cache`


```python
def clean_cache(site_dir: Path) -> None
```



Clean cache and output directories for a cold build.


**Parameters:**

| Name | Type | Default | Description |
|:-----|:-----|:--------|:------------|
| `site_dir` | `Path` | - | *No description provided.* |







**Returns**


`None`




### `run_build`


```python
def run_build(site_dir: Path, name: str, *args: str) -> BuildResult
```



Run a build with given arguments and measure time.


**Parameters:**

| Name | Type | Default | Description |
|:-----|:-----|:--------|:------------|
| `site_dir` | `Path` | - | *No description provided.* |
| `name` | `str` | - | *No description provided.* |







**Returns**


`BuildResult`




### `run_benchmarks`


```python
def run_benchmarks(site_dir: Path, iterations: int = 1) -> list[BuildResult]
```



Run all benchmark configurations.


**Parameters:**

| Name | Type | Default | Description |
|:-----|:-----|:--------|:------------|
| `site_dir` | `Path` | - | *No description provided.* |
| `iterations` | `int` | `1` | *No description provided.* |







**Returns**


`list[BuildResult]`




### `print_summary`


```python
def print_summary(results: list[BuildResult]) -> None
```



Print a summary comparison of all builds.


**Parameters:**

| Name | Type | Default | Description |
|:-----|:-----|:--------|:------------|
| `results` | `list[BuildResult]` | - | *No description provided.* |







**Returns**


`None`




### `main`


```python
def main() -> None
```



Main entry point.



**Returns**


`None`



---
*Generated by Bengal autodoc from `bengal/scripts/benchmark_builds.py`*
