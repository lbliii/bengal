# RFC: Unified Worker Auto-Tune with Fresh Benchmark Calibration

**Status**: Implemented  
**Created**: 2025-12-28  
**Implemented**: 2025-12-28  
**Author**: AI Assistant + Lawrence Lane  
**Priority**: P2 (Medium)  
**Supersedes**: Worker-related sections of `rfc-benchmark-refresh-and-worker-optimization.md`  
**Confidence**: 95% ðŸŸ¢ (implemented and tested)

---

## Executive Summary

Multiple modules in Bengal use `ThreadPoolExecutor` with inconsistent worker-tuning strategies. This RFC proposes:

1. **Unified auto-tune utility** â€” Shared `get_optimal_workers()` with workload-aware scaling
2. **Environment-aware profiles** â€” Auto-detect CI vs local dev vs production
3. **Auto-weight detection** â€” Estimate task complexity from content characteristics
4. **Fresh benchmark suite** â€” Validate optimal thresholds for each module

**Key Insight**: The patitas `parse_many` and `HealthCheck` already implement auto-tune. Other modules use fixed thresholds that may be suboptimal.

### Relationship to Related RFC

This RFC **supersedes** the worker-tuning portions of `rfc-benchmark-refresh-and-worker-optimization.md`. That RFC provided the benchmark data and analysis; this RFC provides the unified implementation.

**From related RFC, we adopt**:
- Default workers formula: `min(max(2, CPU-1), 10)`
- CI-optimized mode concept
- Page complexity ordering concept

**This RFC adds**:
- Unified `bengal/utils/workers.py` module
- WorkloadType-based profiles
- Auto-weight detection for pages
- Environment auto-detection

---

## Problem Statement

### Current State: Inconsistent Patterns

| Module | Threshold | Max Workers | Strategy |
|--------|-----------|-------------|----------|
| `patitas/parse_many` | 5KB total | min(4, n_docs, cpu//2) | Workload-aware âœ… |
| `health_check.py` | 3 validators | min(8, cpu//2, tasks) | Task-aware âœ… |
| `render.py` | 5 pages | max(4, cpu-1) | Fixed threshold âŒ |
| `asset.py` | None | max(4, cpu-1) | No threshold âŒ |
| `graph_builder.py` | 100 pages | max(4, cpu-1) | Fixed threshold âŒ |
| `file_detector.py` | 50 files | min(8, cpu) | Local cap, fixed threshold âŒ |
| `template_detector.py` | 50 files | min(8, cpu) | Local cap, fixed threshold âŒ |
| `related_posts.py` | 50 pages | max(4, cpu-1) | Fixed threshold âŒ |

**Note**: `max(4, cpu-1)` comes from `bengal/config/defaults.py:60`. On a 12-core machine this yields 11 workers, but never below 4.

### Issues

1. **Over-provisioning**: `max(4, cpu-1)` yields 11 workers on a 12-core machine, but benchmarks show 2-4 optimal for most workloads
2. **Under-tuned thresholds**: Fixed thresholds (50, 100) were chosen without benchmark validation
3. **No workload awareness**: CPU-bound and I/O-bound work use same tuning
4. **Inconsistent caps**: Some modules cap at 8, others use global default
5. **No environment awareness**: CI (2 vCPU) gets same config as 12-core dev machine
6. **Missing complexity awareness**: All pages treated equally despite 10x complexity variance

### Evidence: Benchmark Data Shows 2-4 Workers Often Optimal

From `rfc-benchmark-refresh-and-worker-optimization.md`:

| Workload | Optimal Workers | Speedup | Notes |
|----------|-----------------|---------|-------|
| Synthetic (50 pages) | 2-4 | 2.47x | Contention beyond 4 |
| Real site (192 pages) | 8-10 | 2.47x | Heavy pages scale further |
| CI (2 vCPU) | 2 | ~1.5x | Resource constrained |

**Conclusion**: One-size-fits-all `cpu-1` is wrong. Auto-tune based on workload characteristics.

---

## Proposed Solution

### Phase 1: Shared Auto-Tune Utility

Create `bengal/utils/workers.py`:

```python
"""
Worker pool auto-tuning utilities.

Provides workload-aware worker count calculation for ThreadPoolExecutor usage.
Calibrated via benchmarks per RFC: rfc-unified-worker-autotune.md

Key Features:
    - Environment detection (CI vs local vs production)
    - Workload type profiles (CPU-bound, I/O-bound, mixed)
    - Auto-weight detection for pages based on content
    - User config override support
"""

from __future__ import annotations

import os
from dataclasses import dataclass
from enum import Enum
from typing import TYPE_CHECKING, Literal

if TYPE_CHECKING:
    from bengal.core.page import Page


class WorkloadType(Enum):
    """Workload characteristics for auto-tuning."""

    CPU_BOUND = "cpu_bound"      # Parsing, rendering, similarity
    IO_BOUND = "io_bound"        # File stats, asset copying
    MIXED = "mixed"              # Template rendering (I/O + CPU)


class Environment(Enum):
    """Execution environment for tuning profiles."""

    CI = "ci"                    # Constrained CI runner (2-4 vCPU)
    LOCAL = "local"              # Developer machine (8-16 cores)
    PRODUCTION = "production"    # Server deployment (16+ cores)


@dataclass(frozen=True)
class WorkloadProfile:
    """Tuning profile for a workload type."""

    parallel_threshold: int      # Min tasks before parallelizing
    min_workers: int             # Floor for worker count
    max_workers: int             # Ceiling for worker count
    cpu_fraction: float          # Fraction of cores to use


# Calibrated profiles per workload type and environment
# Based on benchmark data from rfc-benchmark-refresh-and-worker-optimization.md
_PROFILES: dict[tuple[WorkloadType, Environment], WorkloadProfile] = {
    # CPU-bound workloads (parsing, similarity, graph building)
    (WorkloadType.CPU_BOUND, Environment.CI):         WorkloadProfile(5, 2, 2, 1.0),
    (WorkloadType.CPU_BOUND, Environment.LOCAL):      WorkloadProfile(5, 2, 4, 0.5),
    (WorkloadType.CPU_BOUND, Environment.PRODUCTION): WorkloadProfile(5, 2, 8, 0.5),

    # I/O-bound workloads (file stats, asset copying)
    (WorkloadType.IO_BOUND, Environment.CI):          WorkloadProfile(20, 2, 4, 1.0),
    (WorkloadType.IO_BOUND, Environment.LOCAL):       WorkloadProfile(20, 2, 8, 0.75),
    (WorkloadType.IO_BOUND, Environment.PRODUCTION):  WorkloadProfile(20, 2, 10, 0.75),

    # Mixed workloads (template rendering: I/O + CPU)
    (WorkloadType.MIXED, Environment.CI):             WorkloadProfile(5, 2, 2, 1.0),
    (WorkloadType.MIXED, Environment.LOCAL):          WorkloadProfile(5, 2, 6, 0.5),
    (WorkloadType.MIXED, Environment.PRODUCTION):     WorkloadProfile(5, 2, 10, 0.5),
}


def detect_environment() -> Environment:
    """
    Auto-detect execution environment for tuning.

    Detection order:
    1. Explicit BENGAL_ENV environment variable
    2. CI environment variables (GitHub Actions, GitLab CI, etc.)
    3. Default to LOCAL

    Returns:
        Detected Environment enum value

    Examples:
        >>> os.environ["CI"] = "true"
        >>> detect_environment()
        Environment.CI
    """
    # Explicit override
    env_value = os.environ.get("BENGAL_ENV", "").lower()
    if env_value == "ci":
        return Environment.CI
    if env_value == "production":
        return Environment.PRODUCTION
    if env_value == "local":
        return Environment.LOCAL

    # CI detection (common CI environment variables)
    ci_indicators = [
        "CI",                    # Generic CI
        "GITHUB_ACTIONS",        # GitHub Actions
        "GITLAB_CI",             # GitLab CI
        "CIRCLECI",              # CircleCI
        "TRAVIS",                # Travis CI
        "JENKINS_URL",           # Jenkins
        "BUILDKITE",             # Buildkite
    ]
    for indicator in ci_indicators:
        if os.environ.get(indicator):
            return Environment.CI

    return Environment.LOCAL


def get_optimal_workers(
    task_count: int,
    *,
    workload_type: WorkloadType = WorkloadType.CPU_BOUND,
    environment: Environment | None = None,
    config_override: int | None = None,
    task_weight: float = 1.0,
) -> int:
    """
    Calculate optimal worker count based on workload characteristics.

    Auto-scales based on:
    - Workload type (CPU-bound vs I/O-bound)
    - Environment (CI vs local vs production)
    - Available CPU cores (fraction based on workload)
    - Task count (no point having more workers than tasks)
    - Optional task weight for heavy/light work estimation

    Args:
        task_count: Number of tasks to process
        workload_type: Type of work (CPU_BOUND, IO_BOUND, MIXED)
        environment: Execution environment (auto-detected if None)
        config_override: User-configured value (bypasses auto-tune if > 0)
        task_weight: Multiplier for task count (>1 for heavy tasks)

    Returns:
        Optimal number of worker threads (always >= 1)

    Examples:
        >>> get_optimal_workers(10, workload_type=WorkloadType.CPU_BOUND)
        2  # Conservative for CPU-bound on local

        >>> get_optimal_workers(100, workload_type=WorkloadType.IO_BOUND)
        6  # More workers for I/O

        >>> get_optimal_workers(5, config_override=16)
        16  # User override respected

        >>> os.environ["CI"] = "true"
        >>> get_optimal_workers(100, workload_type=WorkloadType.MIXED)
        2  # CI mode caps at 2
    """
    # User override takes precedence
    if config_override is not None and config_override > 0:
        return config_override

    # Auto-detect environment if not specified
    if environment is None:
        environment = detect_environment()

    # Get profile for workload type + environment
    profile = _PROFILES[(workload_type, environment)]

    # Calculate CPU-based optimal
    cpu_count = os.cpu_count() or 2
    cpu_optimal = max(profile.min_workers, int(cpu_count * profile.cpu_fraction))
    cpu_optimal = min(cpu_optimal, profile.max_workers)

    # Adjust for task count (weighted)
    effective_tasks = int(task_count * task_weight)

    # Don't use more workers than tasks
    return min(cpu_optimal, max(1, effective_tasks))


def should_parallelize(
    task_count: int,
    *,
    workload_type: WorkloadType = WorkloadType.CPU_BOUND,
    environment: Environment | None = None,
    total_work_estimate: int | None = None,
) -> bool:
    """
    Determine if parallelization is worthwhile for this workload.

    Thread pool overhead (~1-2ms per task) only pays off above threshold.

    Args:
        task_count: Number of tasks to process
        workload_type: Type of work
        environment: Execution environment (auto-detected if None)
        total_work_estimate: Optional size estimate (bytes for parsing, etc.)

    Returns:
        True if parallelization is recommended

    Examples:
        >>> should_parallelize(3, workload_type=WorkloadType.CPU_BOUND)
        False  # Below threshold

        >>> should_parallelize(10, workload_type=WorkloadType.CPU_BOUND)
        True  # Above threshold
    """
    if environment is None:
        environment = detect_environment()

    profile = _PROFILES[(workload_type, environment)]

    # Fast path: below task threshold
    if task_count < profile.parallel_threshold:
        return False

    # Optional: check work size estimate (like patitas does)
    if total_work_estimate is not None and total_work_estimate < 5000:
        return False

    return True


def estimate_page_weight(page: Page) -> float:
    """
    Estimate relative complexity of a page for worker scheduling.

    Heavy pages (autodoc, many code blocks) get higher weights,
    causing them to be scheduled earlier to avoid straggler effect.

    Args:
        page: Page instance to estimate

    Returns:
        Weight multiplier (1.0 = average, >1 = heavy, <1 = light)

    Examples:
        >>> # Simple page
        >>> estimate_page_weight(simple_page)
        1.0

        >>> # Autodoc page with 50 code blocks
        >>> estimate_page_weight(autodoc_page)
        2.5
    """
    weight = 1.0
    content = page.raw_content
    content_len = len(content)

    # Size factor (logarithmic, >10KB starts adding weight)
    if content_len > 10000:
        weight += (content_len - 10000) / 20000  # +0.5 per 10KB above threshold

    # Code block factor (each adds ~50ms render time)
    code_blocks = content.count("```")
    if code_blocks > 5:
        weight += (code_blocks - 5) * 0.1  # +0.1 per block above 5

    # Directive factor (custom directives are expensive)
    directives = content.count("::")
    if directives > 10:
        weight += (directives - 10) * 0.05  # +0.05 per directive above 10

    # Autodoc pages are consistently heavy
    if page.metadata.get("is_autodoc") or page.metadata.get("autodoc"):
        weight += 1.0

    return min(weight, 5.0)  # Cap at 5x to avoid outlier distortion


def order_by_complexity(pages: list[Page], *, descending: bool = True) -> list[Page]:
    """
    Order pages by estimated complexity for optimal worker utilization.

    Scheduling heavy pages first reduces the "straggler effect" where
    one slow page delays overall completion.

    Args:
        pages: List of pages to order
        descending: If True, heaviest first (default for parallel execution)

    Returns:
        Sorted list of pages (new list, does not mutate input)

    Examples:
        >>> ordered = order_by_complexity(pages)
        >>> # Heavy autodoc pages now at front
    """
    return sorted(
        pages,
        key=estimate_page_weight,
        reverse=descending,
    )
```

### Phase 2: Benchmark Suite for Calibration

Extend existing benchmark infrastructure in `benchmarks/calibrate_worker_thresholds.py`:

```python
"""
Benchmark suite to calibrate worker auto-tune thresholds.

Measures break-even points and optimal worker counts for each module.
Run with: python -m benchmarks.calibrate_worker_thresholds

Outputs JSON with recommended thresholds per module.
"""

from __future__ import annotations

import json
import statistics
import time
from concurrent.futures import ThreadPoolExecutor
from dataclasses import dataclass, field
from pathlib import Path
from typing import Callable, TypeVar

T = TypeVar("T")


@dataclass
class CalibrationResult:
    """Result of calibrating a module's worker settings."""

    module: str
    workload_type: str
    break_even_threshold: int      # Tasks where parallel beats sequential
    optimal_workers_small: int     # Best workers for small workloads (<50 tasks)
    optimal_workers_large: int     # Best workers for large workloads (>100 tasks)
    max_useful_workers: int        # Beyond this, performance degrades
    speedup_at_optimal: float      # Speedup vs sequential at optimal
    contention_point: int          # Worker count where adding more hurts
    measurements: dict = field(default_factory=dict)  # Raw timing data


def measure_parallel_execution(
    tasks: list[T],
    processor: Callable[[T], None],
    worker_counts: list[int],
    iterations: int = 3,
) -> dict[int, float]:
    """
    Measure execution time for different worker counts.

    Args:
        tasks: List of work items
        processor: Function to process each task
        worker_counts: Worker counts to test (e.g., [1, 2, 4, 6, 8])
        iterations: Number of iterations per worker count

    Returns:
        Dict mapping worker count to median execution time
    """
    results: dict[int, list[float]] = {w: [] for w in worker_counts}

    for workers in worker_counts:
        for _ in range(iterations):
            start = time.perf_counter()

            if workers == 1:
                # Sequential baseline
                for task in tasks:
                    processor(task)
            else:
                # Parallel execution
                with ThreadPoolExecutor(max_workers=workers) as executor:
                    list(executor.map(processor, tasks))

            elapsed = time.perf_counter() - start
            results[workers].append(elapsed)

    # Return median times
    return {w: statistics.median(times) for w, times in results.items()}


def find_break_even_threshold(
    task_generator: Callable[[int], list[T]],
    processor: Callable[[T], None],
    task_counts: list[int] = [2, 5, 10, 20, 50],
    workers: int = 2,
) -> int:
    """
    Find minimum task count where parallelization beats sequential.

    Args:
        task_generator: Function to generate N tasks
        processor: Function to process each task
        task_counts: Task counts to test
        workers: Worker count for parallel test

    Returns:
        Minimum task count where parallel is faster
    """
    for count in task_counts:
        tasks = task_generator(count)
        times = measure_parallel_execution(
            tasks, processor, [1, workers], iterations=5
        )

        if times[workers] < times[1]:
            return count

    return task_counts[-1]  # Parallel never faster at tested sizes


def calibrate_render_orchestrator() -> CalibrationResult:
    """Benchmark page rendering parallelization."""
    from bengal.core.page import Page
    from bengal.rendering.pipeline import RenderingPipeline
    # ... implementation
    pass


def calibrate_asset_orchestrator() -> CalibrationResult:
    """Benchmark asset processing parallelization."""
    # ... implementation
    pass


def run_all_calibrations() -> None:
    """Run all calibration benchmarks and output recommendations."""
    calibrators = [
        calibrate_render_orchestrator,
        calibrate_asset_orchestrator,
        # ... other calibrators
    ]

    results = []
    for calibrator in calibrators:
        print(f"Running {calibrator.__name__}...")
        result = calibrator()
        if result:
            results.append(result)

    # Output as JSON for consumption
    output = {r.module: r.__dict__ for r in results}
    output_path = Path("benchmarks/calibration_results.json")
    output_path.write_text(json.dumps(output, indent=2))

    # Print summary
    print("\n=== Calibration Summary ===\n")
    for r in results:
        print(f"{r.module} ({r.workload_type}):")
        print(f"  Break-even threshold: {r.break_even_threshold} tasks")
        print(f"  Optimal workers: {r.optimal_workers_small} (small) / {r.optimal_workers_large} (large)")
        print(f"  Contention point: {r.contention_point} workers")
        print(f"  Max speedup: {r.speedup_at_optimal:.2f}x")
        print()


if __name__ == "__main__":
    run_all_calibrations()
```

### Phase 3: Module Adoption

Migrate each module to use the shared utility:

#### 3.1 render.py (High Priority)

```python
# Before (bengal/orchestration/render.py:290)
from bengal.config.defaults import get_max_workers

PARALLEL_THRESHOLD = 5
if parallel and len(pages) >= PARALLEL_THRESHOLD:
    max_workers = get_max_workers(site.config.get("max_workers"))
    with ThreadPoolExecutor(max_workers=max_workers) as executor:
        # ...

# After
from bengal.utils.workers import (
    get_optimal_workers,
    should_parallelize,
    order_by_complexity,
    WorkloadType,
)

if parallel and should_parallelize(len(pages), workload_type=WorkloadType.MIXED):
    # Order heavy pages first to reduce straggler effect
    ordered_pages = order_by_complexity(pages)

    max_workers = get_optimal_workers(
        len(pages),
        workload_type=WorkloadType.MIXED,
        config_override=site.config.get("max_workers"),
    )
    with ThreadPoolExecutor(max_workers=max_workers) as executor:
        # Process ordered_pages instead of pages
        # ...
```

#### 3.2 graph_builder.py (Medium Priority)

```python
# Before (bengal/analysis/graph_builder.py:40)
MIN_PAGES_FOR_PARALLEL = 100
self.parallel = len(site.pages) >= MIN_PAGES_FOR_PARALLEL
max_workers = get_max_workers(site.config.get("max_workers"))

# After
from bengal.utils.workers import (
    get_optimal_workers,
    should_parallelize,
    WorkloadType,
)

self.parallel = should_parallelize(
    len(site.pages),
    workload_type=WorkloadType.CPU_BOUND,
)
if self.parallel:
    self.max_workers = get_optimal_workers(
        len(site.pages),
        workload_type=WorkloadType.CPU_BOUND,
        config_override=site.config.get("max_workers"),
    )
```

#### 3.3 file_detector.py / template_detector.py (Low Priority)

```python
# Before (bengal/orchestration/incremental/file_detector.py:30)
PARALLEL_THRESHOLD = 50
DEFAULT_MAX_WORKERS = min(8, (os.cpu_count() or 4))

def _get_max_workers(site: Site) -> int:
    return site.config.get("max_workers", DEFAULT_MAX_WORKERS)

# After
from bengal.utils.workers import (
    get_optimal_workers,
    should_parallelize,
    WorkloadType,
)

# Remove PARALLEL_THRESHOLD and DEFAULT_MAX_WORKERS constants
# Remove _get_max_workers function

if should_parallelize(len(files), workload_type=WorkloadType.IO_BOUND):
    max_workers = get_optimal_workers(
        len(files),
        workload_type=WorkloadType.IO_BOUND,
        config_override=site.config.get("max_workers"),
    )
```

#### 3.4 Deprecation of get_max_workers()

After all modules are migrated, deprecate `bengal/config/defaults.py:get_max_workers()`:

```python
# bengal/config/defaults.py

import warnings

def get_max_workers(config_value: int | None = None) -> int:
    """
    Resolve max_workers with auto-detection.

    .. deprecated:: 1.0
        Use :func:`bengal.utils.workers.get_optimal_workers` instead.
        This function does not account for workload type or environment.
    """
    warnings.warn(
        "get_max_workers() is deprecated. Use bengal.utils.workers.get_optimal_workers() "
        "for workload-aware worker tuning.",
        DeprecationWarning,
        stacklevel=2,
    )
    if config_value is None or config_value == 0:
        return DEFAULT_MAX_WORKERS
    return max(1, config_value)
```

---

## Calibration Requirements

### Benchmark Methodology

For each module, measure:

1. **Break-even threshold**: Task count where parallel beats sequential
2. **Optimal workers curve**: Plot speedup vs worker count (1, 2, 4, 6, 8, 10, 12)
3. **Contention point**: Where adding workers hurts performance
4. **Workload sensitivity**: How does page complexity affect optimal workers?

### Test Matrix

| Module | Small Workload | Medium Workload | Large Workload |
|--------|----------------|-----------------|----------------|
| render.py | 10 pages | 50 pages | 200 pages |
| graph_builder.py | 50 pages | 200 pages | 1000 pages |
| file_detector.py | 20 files | 100 files | 500 files |
| asset.py | 10 assets | 50 assets | 200 assets |
| related_posts.py | 20 posts | 100 posts | 500 posts |

### Environment Matrix

| Environment | CPU Cores | Detection | Expected Optimal |
|-------------|-----------|-----------|------------------|
| GitHub Actions (free) | 2 | `GITHUB_ACTIONS` | 2 |
| GitHub Actions (4x) | 4 | `GITHUB_ACTIONS` | 2-3 |
| GitLab CI | 2-4 | `GITLAB_CI` | 2 |
| Local dev (M1/M2) | 8-12 | Default | 2-4 |
| Local dev (Intel) | 4-8 | Default | 2-4 |
| Production server | 16+ | `BENGAL_ENV=production` | 4-10 |

### Success Criteria

For each module:
- [ ] Parallel threshold calibrated to Â±10% of break-even
- [ ] Optimal workers validated across environment matrix
- [ ] No performance regression vs current implementation
- [ ] Contention point documented
- [ ] Environment detection verified in CI logs

---

## Implementation Plan

### Phase 1: Foundation (Week 1)

**Goal**: Create the unified workers module with full feature set.

- [ ] Create `bengal/utils/workers.py` with:
  - [ ] `WorkloadType` and `Environment` enums
  - [ ] `WorkloadProfile` dataclass
  - [ ] `_PROFILES` lookup table
  - [ ] `detect_environment()` function
  - [ ] `get_optimal_workers()` function
  - [ ] `should_parallelize()` function
  - [ ] `estimate_page_weight()` function
  - [ ] `order_by_complexity()` function
- [ ] Add comprehensive unit tests in `tests/unit/utils/test_workers.py`
- [ ] Keep existing module code unchanged (parallel development)

### Phase 2: Benchmark Suite (Week 2)

**Goal**: Create calibration infrastructure and gather initial data.

- [ ] Create `benchmarks/calibrate_worker_thresholds.py` with:
  - [ ] `CalibrationResult` dataclass
  - [ ] `measure_parallel_execution()` helper
  - [ ] `find_break_even_threshold()` helper
- [ ] Implement calibration for `render.py` (highest impact)
- [ ] Implement calibration for `graph_builder.py`
- [ ] Run calibration on:
  - [ ] Local dev (M-series Mac)
  - [ ] GitHub Actions free tier (2 vCPU)

### Phase 3: Calibration & Tuning (Week 3)

**Goal**: Validate and refine profile values.

- [ ] Run full calibration suite on multiple environments
- [ ] Analyze results and update `_PROFILES` values
- [ ] Document findings in `benchmarks/CALIBRATION_REPORT.md`
- [ ] Verify environment detection works correctly

### Phase 4: Migration (Week 4)

**Goal**: Migrate modules with highest impact first.

- [ ] Migrate `render.py`:
  - [ ] Import from `bengal.utils.workers`
  - [ ] Add `order_by_complexity()` for page ordering
  - [ ] Remove local `PARALLEL_THRESHOLD` constant
- [ ] Migrate `graph_builder.py`
- [ ] Migrate `related_posts.py`
- [ ] Migrate `file_detector.py` and `template_detector.py`
- [ ] Migrate `asset.py`
- [ ] Add deprecation warning to `bengal/config/defaults.py:get_max_workers()`
- [ ] Run full test suite

### Phase 5: Validation (Week 5)

**Goal**: Ensure no regressions and document improvements.

- [ ] Run benchmark suite comparing before/after
- [ ] Verify CI builds use appropriate worker counts
- [ ] Update `benchmarks/README.md` with new baselines
- [ ] Update developer documentation
- [ ] Create migration guide for external users of `get_max_workers()`

---

## Modules to Migrate

### High Priority (CPU-bound, high impact)

| Module | File | Current Pattern | Notes |
|--------|------|-----------------|-------|
| Page rendering | `orchestration/render.py` | THRESHOLD=5, get_max_workers() | Highest impact |
| Knowledge graph | `analysis/graph_builder.py` | MIN_PAGES=100, get_max_workers() | CPU-bound |
| Related posts | `orchestration/related_posts.py` | MIN_PAGES=50, get_max_workers() | CPU-bound similarity |

### Medium Priority (I/O-bound or already tuned)

| Module | File | Current Pattern | Notes |
|--------|------|-----------------|-------|
| File detection | `orchestration/incremental/file_detector.py` | THRESHOLD=50, min(8, cpu) | I/O-bound |
| Template detection | `orchestration/incremental/template_detector.py` | THRESHOLD=50, min(8, cpu) | I/O-bound |
| Asset processing | `orchestration/asset.py` | get_max_workers() | I/O-bound |

### Already Tuned (Reference implementations)

| Module | File | Pattern | Notes |
|--------|------|---------|-------|
| Health check | `health/health_check.py` | _get_optimal_workers() | Good reference |
| Patitas parser | `rendering/parsers/patitas/__init__.py` | Workload-aware | Best reference |

---

## Risks and Mitigations

| Risk | Likelihood | Impact | Mitigation |
|------|------------|--------|------------|
| Benchmark results vary by hardware | High | Medium | Test on multiple environments; use Environment profiles |
| Over-tuning causes regressions | Medium | High | A/B test against current; keep config_override |
| Thresholds become stale | Low | Medium | Document calibration methodology; re-run quarterly |
| CI environment differs from local | High | Medium | Auto-detect CI via environment variables |
| Environment detection fails | Low | Medium | Fall back to LOCAL; allow explicit BENGAL_ENV |
| Page weight estimation inaccurate | Medium | Low | Cap at 5x; ordering is best-effort optimization |
| Migration breaks external users | Low | High | Deprecation warning before removal; migration guide |

---

## Future Work

### Runtime Telemetry (Deferred)

For future consideration: opt-in telemetry to enable continuous calibration.

```python
# Future: bengal/utils/telemetry.py

def record_parallel_execution(
    module: str,
    task_count: int,
    workers_used: int,
    elapsed_seconds: float,
    environment: Environment,
) -> None:
    """Record parallel execution metrics for future tuning.

    Only active when BENGAL_TELEMETRY=1.
    Data stored locally in .bengal-telemetry.json.
    """
    if not os.environ.get("BENGAL_TELEMETRY"):
        return

    # Append to local file for later analysis
    # ...
```

**Benefits**:
- Real-world calibration data from diverse environments
- Automatic detection of profile drift
- Per-site tuning recommendations

**Concerns**:
- Privacy (opt-in only)
- Storage overhead
- Analysis tooling needed

**Decision**: Defer to future RFC. Current benchmark-based calibration is sufficient.

---

## Success Metrics

| Metric | Current | Target | How to Measure |
|--------|---------|--------|----------------|
| Worker over-provisioning | Common (11 on 12-core) | Rare (2-4 typical) | Audit worker counts in logs |
| CI worker count | 11 (ignores 2 vCPU) | 2 (matches vCPU) | CI build logs |
| Parallel threshold accuracy | Unvalidated | Â±10% of break-even | Benchmark calibration |
| Code patterns | 3+ patterns | 1 shared utility | Code review / grep |
| Performance regression | N/A | None | Benchmark comparison |
| Page ordering | Random | Complexity-ordered | Verify heavy pages first |

### Quantitative Targets (from Related RFC)

| Metric | Current | Target | Method |
|--------|---------|--------|--------|
| 192-page build (10 workers) | 17s | 14s | Template + ordering |
| CI build time (2 vCPU) | 26s | 20s | CI mode + environment detection |
| Render @ 1 worker | 3.55s | 3.55s | No regression |
| 10-worker efficiency | 25% | 35% | Reduce contention via ordering |

---

## Appendix: Current Code Locations

### Files to Create

```
bengal/utils/workers.py              # NEW: Unified worker utility
tests/unit/utils/test_workers.py     # NEW: Unit tests
benchmarks/calibrate_worker_thresholds.py  # NEW: Calibration suite
benchmarks/CALIBRATION_REPORT.md     # NEW: Results documentation
```

### Files to Modify

| File | Line | Current | Change |
|------|------|---------|--------|
| `bengal/orchestration/render.py` | ~290 | `PARALLEL_THRESHOLD = 5` | Import from workers.py |
| `bengal/analysis/graph_builder.py` | ~40 | `MIN_PAGES_FOR_PARALLEL = 100` | Import from workers.py |
| `bengal/orchestration/related_posts.py` | ~50 | `MIN_PAGES_FOR_PARALLEL = 50` | Import from workers.py |
| `bengal/orchestration/incremental/file_detector.py` | ~30 | `PARALLEL_THRESHOLD = 50` | Import from workers.py |
| `bengal/orchestration/incremental/template_detector.py` | ~34 | `PARALLEL_THRESHOLD = 50` | Import from workers.py |
| `bengal/orchestration/asset.py` | ~33 | `from ... import get_max_workers` | Import from workers.py |
| `bengal/config/defaults.py` | ~63 | `def get_max_workers()` | Add deprecation warning |

### Reference Implementations (patterns to follow)

```
bengal/health/health_check.py:214-239        # _get_optimal_workers() - good task-aware pattern
bengal/rendering/parsers/patitas/__init__.py:181-257  # parse_many() - best workload-aware pattern
```

---

## Design Decisions

### Q1: Should we support environment-specific profiles?

**Answer: Yes** â€” Implemented via `Environment` enum and `detect_environment()`.

CI runners (2 vCPU) should not use the same worker count as a 12-core dev machine.
Environment is auto-detected from common CI environment variables but can be
overridden via `BENGAL_ENV`.

### Q2: Should task_weight be auto-detected?

**Answer: Yes** â€” Implemented via `estimate_page_weight()` and `order_by_complexity()`.

Page complexity varies 10x (simple markdown vs heavy autodoc). Auto-detection uses:
- Content size (bytes)
- Code block count
- Directive count
- Autodoc flag

Heavy pages are scheduled first to reduce the straggler effect.

### Q3: Should we add runtime telemetry?

**Answer: Optional** â€” Deferred to future RFC.

Telemetry would enable continuous calibration but adds complexity. For now,
periodic benchmark re-runs are sufficient. A future RFC could add opt-in
telemetry via `BENGAL_TELEMETRY=1`.

---

## Testing Strategy

### Unit Tests for workers.py

```python
# tests/unit/utils/test_workers.py

import os
import pytest
from unittest.mock import patch

from bengal.utils.workers import (
    WorkloadType,
    Environment,
    detect_environment,
    get_optimal_workers,
    should_parallelize,
    estimate_page_weight,
    order_by_complexity,
)


class TestDetectEnvironment:
    """Test environment auto-detection."""

    def test_explicit_override(self):
        with patch.dict(os.environ, {"BENGAL_ENV": "production"}):
            assert detect_environment() == Environment.PRODUCTION

    def test_github_actions_detection(self):
        with patch.dict(os.environ, {"GITHUB_ACTIONS": "true"}, clear=True):
            assert detect_environment() == Environment.CI

    def test_default_to_local(self):
        with patch.dict(os.environ, {}, clear=True):
            assert detect_environment() == Environment.LOCAL


class TestGetOptimalWorkers:
    """Test worker count calculation."""

    def test_user_override_respected(self):
        result = get_optimal_workers(100, config_override=16)
        assert result == 16

    def test_ci_caps_at_2(self):
        with patch.dict(os.environ, {"CI": "true"}):
            result = get_optimal_workers(
                100,
                workload_type=WorkloadType.CPU_BOUND,
            )
            assert result <= 2

    def test_never_more_workers_than_tasks(self):
        result = get_optimal_workers(3, workload_type=WorkloadType.IO_BOUND)
        assert result <= 3

    def test_minimum_one_worker(self):
        result = get_optimal_workers(0)
        assert result >= 1


class TestShouldParallelize:
    """Test parallelization decision logic."""

    def test_below_threshold_returns_false(self):
        assert not should_parallelize(2, workload_type=WorkloadType.CPU_BOUND)

    def test_above_threshold_returns_true(self):
        assert should_parallelize(20, workload_type=WorkloadType.CPU_BOUND)

    def test_small_work_estimate_returns_false(self):
        assert not should_parallelize(
            100,
            workload_type=WorkloadType.CPU_BOUND,
            total_work_estimate=1000,  # < 5000 bytes
        )


class TestEstimatePageWeight:
    """Test page complexity estimation."""

    def test_simple_page_weight_near_one(self, simple_page):
        weight = estimate_page_weight(simple_page)
        assert 0.8 <= weight <= 1.2

    def test_autodoc_page_gets_bonus(self, autodoc_page):
        weight = estimate_page_weight(autodoc_page)
        assert weight >= 2.0

    def test_weight_capped_at_five(self, huge_page):
        weight = estimate_page_weight(huge_page)
        assert weight <= 5.0
```

### Integration Tests

```python
# tests/integration/test_worker_integration.py

def test_render_uses_workers_utility(site_with_pages):
    """Verify render.py uses the new workers utility."""
    from bengal.orchestration.render import RenderOrchestrator

    orchestrator = RenderOrchestrator(site_with_pages)
    # Verify it imports from bengal.utils.workers
    # ...


def test_ci_environment_uses_fewer_workers(site_with_pages):
    """Verify CI mode caps worker count."""
    import os
    from bengal.utils.workers import get_optimal_workers, WorkloadType

    with patch.dict(os.environ, {"CI": "true"}):
        workers = get_optimal_workers(
            len(site_with_pages.pages),
            workload_type=WorkloadType.MIXED,
        )
        assert workers <= 2
```

---

## References

- `plan/drafted/rfc-benchmark-refresh-and-worker-optimization.md` â€” Benchmark data and analysis
- `bengal/rendering/parsers/patitas/__init__.py:181` â€” parse_many() reference implementation
- `bengal/health/health_check.py:219` â€” _get_optimal_workers() reference implementation
- `bengal/config/defaults.py:59-85` â€” Current get_max_workers() to deprecate
- Python PEP 703 â€” Free-threaded Python (enables true parallelism)
