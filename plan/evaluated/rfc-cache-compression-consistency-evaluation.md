# RFC Evaluation: Cache Compression Consistency

**RFC**: `plan/drafted/rfc-cache-compression-consistency.md`  
**Evaluated**: 2025-12-25  
**Status**: âœ… **APPROVED with Minor Corrections**

---

## Executive Summary

The RFC proposes migrating three auxiliary cache files (`taxonomy_index.json`, `asset_deps.json`, `page_metadata.json`) from raw JSON to compressed `.json.zst` format using existing compression infrastructure. This is a **sound proposal** that will reduce cache size by ~40% with minimal implementation effort.

**Verdict**: âœ… **APPROVE** - Proceed with implementation after addressing the corrections below.

---

## Problem Statement Validation âœ…

**Claim**: Three auxiliary caches use raw JSON, bypassing compression.

**Verified**:
- âœ… `TaxonomyIndex.save_to_disk()` (line 197-198): Uses `json.dump()` directly
- âœ… `AssetDependencyMap.save_to_disk()` (line 186-187): Uses `json.dump()` with `AtomicFile`
- âœ… `PageDiscoveryCache.save_to_disk()` (line 189-191): Uses `json.dump()` with `AtomicFile`

**Size Impact**: RFC claims ~2.8M savings (40%). This aligns with compression benchmarks showing 92-93% reduction. **Verified âœ…**

---

## Technical Approach Validation

### âœ… Compression Infrastructure Exists

**Claim**: `CacheStore` and compression utilities are available.

**Verified**:
- âœ… `bengal/cache/compression.py` provides `save_compressed()` and `load_compressed()`
- âœ… `load_auto()` exists (line 218) - provides automatic format detection with fallback
- âœ… Compression utilities handle version headers, atomic writes, and error handling

### âš ï¸ Function Name Correction Required

**Issue**: RFC references `load_with_fallback()` which **does not exist**.

**Actual Function**: `load_auto()` in `bengal/cache/compression.py:218`

**Correction Needed**:
```python
# RFC says:
from bengal.cache.compression import save_compressed, load_with_fallback

# Should be:
from bengal.cache.compression import save_compressed, load_auto
```

**Impact**: Low - simple rename in implementation.

---

## Implementation Plan Review

### Phase 1: Migrate to Compression âœ…

**Approach**: Replace `json.dump()` with `save_compressed()`, use `load_auto()` for loading.

**Validation**:
- âœ… Pattern is correct
- âœ… Backward compatibility handled via `load_auto()` fallback
- âš ï¸ **Correction**: Use `load_auto()` not `load_with_fallback()`

**Code Pattern Verification**:

**Current Pattern** (TaxonomyIndex):
```197:198:bengal/cache/taxonomy_index.py
            with open(self.cache_path, "w") as f:
                json.dump(data, f, indent=2)
```

**Proposed Pattern** (Correct):
```python
from bengal.cache.compression import save_compressed, load_auto

def save_to_disk(self) -> None:
    data = {...}
    compressed_path = self.cache_path.with_suffix(".json.zst")
    save_compressed(data, compressed_path)

def _load_from_disk(self) -> None:
    try:
        data = load_auto(self.cache_path)  # Auto-detects .json.zst or .json
        # ... rest of loading logic
    except FileNotFoundError:
        self.tags = {}
        self._page_to_tags = {}
```

**Note**: `load_auto()` already handles:
- Trying `.json.zst` first
- Falling back to `.json` if not found
- Raising `FileNotFoundError` if neither exists

### Phase 2: Update BengalPaths âš ï¸

**RFC Claim**: Update paths to `.json.zst` extensions.

**Reality Check**:
- Current paths return `.json` (lines 105-117 in `paths.py`)
- `load_auto()` handles path resolution automatically
- **Recommendation**: Keep paths as `.json` for backward compatibility during migration
- Update docstrings to mention compression, but keep path names unchanged

**Correction**:
```python
@property
def taxonomy_cache(self) -> Path:
    """Taxonomy index cache file (.bengal/taxonomy_index.json or .json.zst)."""
    return self.state_dir / "taxonomy_index.json"
```

**Rationale**: `load_auto()` and `save_compressed()` handle the `.zst` extension automatically. Keeping paths as `.json` maintains compatibility and allows `load_auto()` to do its job.

### Phase 3: Clean Command Update âœ…

**RFC Claim**: Update `bengal clean --cache` to clean both formats.

**Reality Check**:
- Current implementation (line 98-99) removes entire `.bengal/` directory
- This **already cleans both formats** automatically
- **No code changes needed** - current implementation is sufficient

**Verification**:
```98:99:bengal/cli/commands/clean.py
    if clean_cache and site.paths.state_dir.exists():
        site._rmtree_robust(site.paths.state_dir)
```

**Verdict**: âœ… No changes needed - current implementation already handles both formats.

---

## Migration Strategy Validation âœ…

### Backward Compatibility

**RFC Claim**: `load_with_fallback()` provides seamless migration.

**Reality**: `load_auto()` provides this functionality (line 218-249 in `compression.py`).

**Verified Behavior**:
1. âœ… Tries `.json.zst` first
2. âœ… Falls back to `.json` if not found
3. âœ… Raises `FileNotFoundError` if neither exists
4. âœ… Handles version mismatches gracefully

**Migration Flow**:
1. **v0.1.7**: Save compressed, load both formats âœ…
2. **v0.2.0**: Remove fallback (optional breaking change)

**Verdict**: âœ… Migration strategy is sound.

---

## Size Impact Validation âœ…

**RFC Claims**:
- Before: 5.8M total
- After: ~3.0M total
- Savings: ~2.8M (48%)

**Validation**:
- Compression ratio: 92-93% (verified in `compression.py` comments)
- Math checks out: 1.5M â†’ ~120K (92%), 1.3M â†’ ~104K (92%), 200K â†’ ~16K (92%)
- **Total savings**: ~2.76M (matches RFC claim of ~2.8M)

**Verdict**: âœ… Size impact claims are accurate.

---

## Performance Impact Validation âœ…

**RFC Claims**:
- Compress: <1ms per file
- Decompress: <0.3ms per file
- Total build impact: <3ms

**Verified**:
- Benchmarks documented in `compression.py:7-11`
- Three files Ã— <1ms = <3ms total âœ…
- Negligible impact confirmed

**Verdict**: âœ… Performance claims are accurate.

---

## Testing Requirements âœ…

**RFC Lists**:
1. Unit tests for round-trip serialization âœ…
2. Migration test (load old `.json`, save new `.zst`) âœ…
3. Build test (full site build, verify sizes) âœ…
4. Clean test (verify both formats removed) âœ…

**Additional Recommendations**:
- Test `load_auto()` fallback behavior
- Test version mismatch handling
- Test atomic write behavior (crash safety)

**Verdict**: âœ… Testing plan is comprehensive.

---

## Code Changes Estimate âœ…

**RFC Estimate**: ~100 lines changed

**Breakdown**:
- TaxonomyIndex: ~30 lines âœ…
- AssetDependencyMap: ~30 lines âœ…
- PageDiscoveryCache: ~30 lines âœ…
- paths.py: ~10 lines (docstrings only) âœ…
- clean.py: 0 lines (no changes needed) âœ…

**Total**: ~100 lines âœ…

**Verdict**: âœ… Estimate is accurate.

---

## Critical Issues Found

### 1. Function Name Error âš ï¸

**Severity**: Low  
**Impact**: Implementation will fail if not corrected

**Issue**: RFC references `load_with_fallback()` which doesn't exist.

**Fix**: Replace with `load_auto()` throughout RFC and implementation.

**Location**: RFC lines 91, 104, 152, 155, 186-188

### 2. Path Updates Unnecessary âš ï¸

**Severity**: Low  
**Impact**: Over-engineering

**Issue**: RFC proposes changing `BengalPaths` to return `.json.zst` paths.

**Fix**: Keep paths as `.json`. `load_auto()` and `save_compressed()` handle extension automatically.

**Rationale**: Maintains backward compatibility and allows `load_auto()` to work correctly.

### 3. Clean Command Update Unnecessary âœ…

**Severity**: None  
**Impact**: None

**Issue**: RFC suggests updating clean command, but current implementation already handles both formats.

**Fix**: No changes needed.

---

## Recommendations

### Must Fix Before Implementation

1. âœ… **Replace `load_with_fallback()` with `load_auto()`** in RFC and implementation
2. âœ… **Keep `BengalPaths` paths as `.json`** - update docstrings only
3. âœ… **Skip clean command changes** - current implementation is sufficient

### Nice to Have

1. Add migration helper function to convert existing `.json` files to `.zst` on first load
2. Add cache size reporting to `bengal stats` command
3. Document compression in user-facing docs

---

## Final Verdict

### âœ… APPROVED with Corrections

**Confidence**: ðŸŸ¢ **High (95%)**

**Rationale**:
- Problem is real and well-documented âœ…
- Solution is technically sound âœ…
- Infrastructure exists and is tested âœ…
- Migration strategy is safe âœ…
- Performance impact is negligible âœ…
- Size savings are significant âœ…

**Required Corrections**:
1. Replace `load_with_fallback()` â†’ `load_auto()`
2. Keep `BengalPaths` paths as `.json` (update docstrings only)
3. Skip clean command changes

**Risk Assessment**: ðŸŸ¢ **Low Risk**
- Backward compatible migration âœ…
- Existing infrastructure tested âœ…
- Simple code changes âœ…
- Easy rollback if issues arise âœ…

---

## Implementation Checklist (Corrected)

- [ ] Update `TaxonomyIndex.save_to_disk()` to use `save_compressed()`
- [ ] Update `TaxonomyIndex._load_from_disk()` to use `load_auto()`
- [ ] Update `AssetDependencyMap.save_to_disk()` to use `save_compressed()`
- [ ] Update `AssetDependencyMap._load_from_disk()` to use `load_auto()`
- [ ] Update `PageDiscoveryCache.save_to_disk()` to use `save_compressed()`
- [ ] Update `PageDiscoveryCache._load_from_disk()` to use `load_auto()`
- [ ] Update `BengalPaths` docstrings (keep paths as `.json`)
- [ ] Add unit tests for round-trip serialization
- [ ] Add migration test (load old `.json`, save new `.zst`)
- [ ] Verify backward compatibility with existing `.json` caches
- [ ] Test full build cycle with compressed caches
- [ ] Verify cache sizes match expected compression ratios

---

## References

- **RFC**: `plan/drafted/rfc-cache-compression-consistency.md`
- **Compression Module**: `bengal/cache/compression.py`
- **CacheStore**: `bengal/cache/cache_store.py`
- **TaxonomyIndex**: `bengal/cache/taxonomy_index.py`
- **AssetDependencyMap**: `bengal/cache/asset_dependency_map.py`
- **PageDiscoveryCache**: `bengal/cache/page_discovery_cache.py`
- **BengalPaths**: `bengal/cache/paths.py`
- **Clean Command**: `bengal/cli/commands/clean.py`
