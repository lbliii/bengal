[pytest]
addopts = --benchmark-only
          --benchmark-warmup=on
          --benchmark-save-data
          --benchmark-compare=0001
markers =
    benchmark: mark a test as a benchmark
    regression: mark tests that track regressions

# Uncomment below to enable additional features:

# COMPARISON & REGRESSION DETECTION
# --benchmark-compare: Compare against a previous run (0001 = last run)
# --benchmark-compare-fail: Fail if regression exceeds threshold (e.g., mean:10%)
; --benchmark-compare-fail=mean:10%

# HISTORICAL DATA
# --benchmark-save: Save results with a name (e.g., baseline, v0.1.3)
# --benchmark-save-data: Include extra data (memory, GC, etc) in results
; --benchmark-save=baseline

# PROFILING & ANALYSIS
# --benchmark-cprofile: Profile with cProfile and save results
# --benchmark-json: Export results to JSON for analysis
# --benchmark-histogram: Generate histogram of results
; --benchmark-cprofile=cpu
; --benchmark-json=.benchmarks/results.json
; --benchmark-histogram=.benchmarks/histogram

# OUTPUT FORMATTING
# --benchmark-sort: Sort results by column (name, mean, stddev, etc)
# --benchmark-group-by: Group results by (func, args, params)
# --benchmark-columns: Select which columns to display
; --benchmark-sort=mean
; --benchmark-group-by=func
; --benchmark-columns=min,max,mean,stddev,median,iqr,outliers,ops,rounds

# PRECISION & TIME
# --benchmark-min-rounds: Minimum number of benchmark rounds (default: 5)
# --benchmark-min-time: Minimum time for a benchmark in seconds
# --benchmark-max-time: Maximum time for a benchmark in seconds
; --benchmark-min-rounds=10
; --benchmark-min-time=0.0001
; --benchmark-max-time=1.0

# WARMUP
# --benchmark-warmup-iterations: Number of warmup iterations
; --benchmark-warmup-iterations=100000

# VERBOSITY
# --benchmark-verbose: Verbose benchmark output
# --benchmark-quiet: Quiet output
; --benchmark-verbose
