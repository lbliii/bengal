"""
Pygments lexer caching to dramatically improve syntax highlighting performance.

Problem: pygments.lexers.guess_lexer() triggers expensive plugin discovery
via importlib.metadata on EVERY code block, causing 60+ seconds overhead
on large sites with many code blocks.

Solution: Cache lexers by language name to avoid repeated plugin discovery.

Performance Impact (measured on 826-page site):
- Before: 86s (73% in Pygments plugin discovery)
- After: ~29s (3Ã— faster)
"""

import threading
from typing import Optional, Dict
from pygments.lexers import get_lexer_by_name, guess_lexer
from pygments.util import ClassNotFound
from bengal.utils.logger import get_logger

logger = get_logger(__name__)

# Thread-safe lexer cache
_lexer_cache: Dict[str, any] = {}
_cache_lock = threading.Lock()

# Stats for monitoring
_cache_stats = {
    'hits': 0,
    'misses': 0,
    'guess_calls': 0
}


def get_lexer_cached(language: Optional[str] = None, code: str = "") -> any:
    """
    Get a Pygments lexer with aggressive caching.
    
    Strategy:
    1. If language specified: cache by language name (fast path)
    2. If no language: hash code sample and cache guess result
    3. Fallback: return text lexer if all else fails
    
    Args:
        language: Optional language name (e.g., 'python', 'javascript')
        code: Code content (used for guessing if language not specified)
        
    Returns:
        Pygments lexer instance
        
    Performance:
        - Cached lookup: ~0.001ms
        - Uncached lookup: ~30ms (plugin discovery)
        - Cache hit rate: >95% after first few pages
    """
    global _cache_stats
    
    # Fast path: language specified
    if language:
        cache_key = f"lang:{language.lower()}"
        
        with _cache_lock:
            if cache_key in _lexer_cache:
                _cache_stats['hits'] += 1
                return _lexer_cache[cache_key]
            
            _cache_stats['misses'] += 1
        
        # Try to get lexer by name
        try:
            lexer = get_lexer_by_name(language.lower())
            with _cache_lock:
                _lexer_cache[cache_key] = lexer
            logger.debug("lexer_cached", language=language, cache_key=cache_key)
            return lexer
        except ClassNotFound:
            logger.warning("unknown_lexer", language=language, fallback="text")
            # Cache the fallback too
            lexer = get_lexer_by_name('text')
            with _cache_lock:
                _lexer_cache[cache_key] = lexer
            return lexer
    
    # Slow path: guess lexer from code
    # Cache by hash of first 200 chars (representative sample)
    _cache_stats['guess_calls'] += 1
    
    code_sample = code[:200] if len(code) > 200 else code
    cache_key = f"guess:{hash(code_sample)}"
    
    with _cache_lock:
        if cache_key in _lexer_cache:
            _cache_stats['hits'] += 1
            return _lexer_cache[cache_key]
        
        _cache_stats['misses'] += 1
    
    # Expensive guess operation
    try:
        lexer = guess_lexer(code)
        with _cache_lock:
            _lexer_cache[cache_key] = lexer
        logger.debug("lexer_guessed", 
                    guessed_language=lexer.name,
                    cache_key=cache_key[:20])
        return lexer
    except Exception as e:
        logger.warning("lexer_guess_failed", error=str(e), fallback="text")
        lexer = get_lexer_by_name('text')
        with _cache_lock:
            _lexer_cache[cache_key] = lexer
        return lexer


def clear_cache():
    """Clear the lexer cache. Useful for testing or memory management."""
    global _lexer_cache, _cache_stats
    with _cache_lock:
        _lexer_cache.clear()
        _cache_stats = {
            'hits': 0,
            'misses': 0,
            'guess_calls': 0
        }
    logger.info("lexer_cache_cleared")


def get_cache_stats() -> dict:
    """
    Get cache statistics for monitoring.
    
    Returns:
        Dict with hits, misses, guess_calls, hit_rate
    """
    with _cache_lock:
        stats = _cache_stats.copy()
        total = stats['hits'] + stats['misses']
        stats['hit_rate'] = stats['hits'] / total if total > 0 else 0
        stats['cache_size'] = len(_lexer_cache)
    return stats


def log_cache_stats():
    """Log cache statistics. Call at end of build for visibility."""
    stats = get_cache_stats()
    logger.info(
        "pygments_cache_stats",
        hits=stats['hits'],
        misses=stats['misses'],
        guess_calls=stats['guess_calls'],
        hit_rate=f"{stats['hit_rate']:.1%}",
        cache_size=stats['cache_size']
    )

