"""
Content migration assistant for safe content restructuring.

Provides tools to safely move, split, merge, and reorganize content files
while maintaining link integrity and generating necessary redirects.

Key Features:
    - Preview moves before executing
    - Automatic redirect generation
    - Link update across the site
    - Split large pages into smaller ones
    - Merge related pages

Related Modules:
    - bengal.health.validators.links: Link validation
    - bengal.analysis.knowledge_graph: Content relationships
    - bengal.debug.base: Debug tool infrastructure

See Also:
    - bengal/postprocess/redirects.py: Redirect handling
"""

from __future__ import annotations

import re
from dataclasses import dataclass, field
from pathlib import Path
from typing import TYPE_CHECKING, Any

from bengal.debug.base import DebugFinding, DebugRegistry, DebugReport, DebugTool, Severity
from bengal.utils.logger import get_logger

logger = get_logger(__name__)

if TYPE_CHECKING:
    pass


@dataclass
class MoveOperation:
    """
    A planned content move operation.

    Attributes:
        source: Source path (relative to content dir)
        destination: Destination path (relative to content dir)
        reason: Why this move is happening
    """

    source: str
    destination: str
    reason: str = ""

    def __str__(self) -> str:
        return f"{self.source} â†’ {self.destination}"


@dataclass
class LinkUpdate:
    """
    A link that needs to be updated.

    Attributes:
        file_path: File containing the link
        old_link: Current link target
        new_link: New link target
        line: Line number in file
        context: Surrounding text context
    """

    file_path: str
    old_link: str
    new_link: str
    line: int = 0
    context: str = ""


@dataclass
class Redirect:
    """
    A redirect rule for moved content.

    Attributes:
        from_path: Old URL path
        to_path: New URL path
        status_code: HTTP status code (301 permanent, 302 temporary)
    """

    from_path: str
    to_path: str
    status_code: int = 301

    def to_nginx(self) -> str:
        """Generate nginx redirect rule."""
        return f"rewrite ^{self.from_path}$ {self.to_path} permanent;"

    def to_netlify(self) -> str:
        """Generate Netlify _redirects format."""
        return f"{self.from_path} {self.to_path} {self.status_code}"

    def to_apache(self) -> str:
        """Generate Apache .htaccess rule."""
        return f"Redirect {self.status_code} {self.from_path} {self.to_path}"


@dataclass
class MovePreview:
    """
    Preview of what a move operation would do.

    Attributes:
        operation: The move operation being previewed
        affected_links: Links that would need updating
        redirects_needed: Redirects that would be generated
        warnings: Any warnings about the move
        can_proceed: Whether the move can safely proceed
    """

    operation: MoveOperation
    affected_links: list[LinkUpdate] = field(default_factory=list)
    redirects_needed: list[Redirect] = field(default_factory=list)
    warnings: list[str] = field(default_factory=list)
    can_proceed: bool = True

    def format_summary(self) -> str:
        """Format preview as summary."""
        lines = [f"ðŸ“¦ Move Preview: {self.operation}"]
        lines.append("")

        if self.affected_links:
            lines.append(f"ðŸ”— {len(self.affected_links)} links would be updated:")
            for link in self.affected_links[:5]:
                lines.append(f"   â€¢ {link.file_path}:{link.line}")
            if len(self.affected_links) > 5:
                lines.append(f"   ... and {len(self.affected_links) - 5} more")
            lines.append("")

        if self.redirects_needed:
            lines.append(f"â†ªï¸  {len(self.redirects_needed)} redirect(s) would be created:")
            for redirect in self.redirects_needed:
                lines.append(f"   â€¢ {redirect.from_path} â†’ {redirect.to_path}")
            lines.append("")

        if self.warnings:
            lines.append("âš ï¸  Warnings:")
            for warning in self.warnings:
                lines.append(f"   â€¢ {warning}")
            lines.append("")

        status = "âœ… Safe to proceed" if self.can_proceed else "âŒ Issues found"
        lines.append(status)

        return "\n".join(lines)


@dataclass
class PageDraft:
    """
    A draft of a new or modified page.

    Used for split/merge operations to preview changes before applying.

    Attributes:
        path: Target path for the page
        title: Page title
        content: Page content (markdown)
        frontmatter: Page frontmatter
        source_pages: Original pages this was derived from
    """

    path: str
    title: str
    content: str
    frontmatter: dict[str, Any] = field(default_factory=dict)
    source_pages: list[str] = field(default_factory=list)

    def format_preview(self, max_lines: int = 20) -> str:
        """Format as preview."""
        lines = [f"ðŸ“„ {self.path}"]
        lines.append(f"   Title: {self.title}")
        if self.source_pages:
            lines.append(f"   From: {', '.join(self.source_pages)}")
        lines.append("")
        lines.append("   Content preview:")

        content_lines = self.content.split("\n")[:max_lines]
        for line in content_lines:
            lines.append(f"   â”‚ {line[:60]}")
        if len(self.content.split("\n")) > max_lines:
            lines.append(f"   â”‚ ... ({len(self.content.split(chr(10))) - max_lines} more lines)")

        return "\n".join(lines)


@DebugRegistry.register
class ContentMigrator(DebugTool):
    """
    Tool for safely restructuring content.

    Helps move, split, merge, and reorganize content while maintaining
    link integrity and generating necessary redirects.

    Creation:
        migrator = ContentMigrator(site=site)

    Example:
        >>> migrator = ContentMigrator(site=site)
        >>> preview = migrator.preview_move("docs/old.md", "guides/new.md")
        >>> print(preview.format_summary())
        >>> if preview.can_proceed:
        ...     migrator.execute_move(preview)
    """

    name = "migrate"
    description = "Safely restructure content"

    def analyze(self) -> DebugReport:
        """
        Analyze content structure for migration opportunities.

        Returns:
            DebugReport with structure analysis
        """
        report = self.create_report()
        report.summary = "Content structure analysis"

        if not self.site:
            report.add_finding(
                title="Site not available",
                description="Cannot analyze without site instance",
                severity=Severity.ERROR,
            )
            return report

        # Find potential issues
        findings = self._find_structure_issues()
        report.findings.extend(findings)

        # Generate recommendations
        report.recommendations = self._generate_recommendations(report)

        return report

    def preview_move(self, source: str, destination: str) -> MovePreview:
        """
        Preview what would happen if a file is moved.

        Args:
            source: Source path (relative to content dir)
            destination: Destination path

        Returns:
            MovePreview with affected links and redirects
        """
        operation = MoveOperation(source=source, destination=destination)
        preview = MovePreview(operation=operation)

        if not self.site:
            preview.warnings.append("Site not available - limited preview")
            return preview

        # Find links that reference the source
        source_url = self._path_to_url(source)
        dest_url = self._path_to_url(destination)

        for page in self.site.pages:
            content = getattr(page, "content", "") or ""
            page_path = str(getattr(page, "source_path", ""))

            # Find links to source
            for match in re.finditer(r"\[([^\]]*)\]\(([^)]+)\)", content):
                link_target = match.group(2)
                if self._links_match(link_target, source_url):
                    line = content[: match.start()].count("\n") + 1
                    preview.affected_links.append(
                        LinkUpdate(
                            file_path=page_path,
                            old_link=link_target,
                            new_link=self._update_link(link_target, dest_url),
                            line=line,
                            context=match.group(0),
                        )
                    )

        # Generate redirect
        preview.redirects_needed.append(Redirect(from_path=source_url, to_path=dest_url))

        # Check for issues
        dest_path = self.root_path / destination
        if dest_path.exists():
            preview.warnings.append(f"Destination already exists: {destination}")
            preview.can_proceed = False

        source_path = self.root_path / source
        if not source_path.exists():
            preview.warnings.append(f"Source does not exist: {source}")
            preview.can_proceed = False

        return preview

    def execute_move(
        self,
        preview: MovePreview,
        update_links: bool = True,
        create_redirects: bool = True,
        dry_run: bool = False,
    ) -> list[str]:
        """
        Execute a previewed move operation.

        Args:
            preview: Move preview from preview_move()
            update_links: Whether to update links in other files
            create_redirects: Whether to generate redirect rules
            dry_run: If True, only report what would be done

        Returns:
            List of actions taken (or that would be taken)
        """
        actions: list[str] = []

        if not preview.can_proceed:
            return ["Move cancelled due to warnings"]

        source_path = self.root_path / preview.operation.source
        dest_path = self.root_path / preview.operation.destination

        # Move the file
        if not dry_run:
            dest_path.parent.mkdir(parents=True, exist_ok=True)
            source_path.rename(dest_path)
        actions.append(f"Moved {preview.operation.source} â†’ {preview.operation.destination}")

        # Update links
        if update_links:
            for link_update in preview.affected_links:
                if not dry_run:
                    self._update_file_link(link_update)
                actions.append(f"Updated link in {link_update.file_path}:{link_update.line}")

        # Create redirects
        if create_redirects and preview.redirects_needed:
            redirects_path = self.root_path / "_redirects"
            redirect_lines = [r.to_netlify() for r in preview.redirects_needed]

            if not dry_run:
                existing = redirects_path.read_text() if redirects_path.exists() else ""
                new_content = existing + "\n".join(redirect_lines) + "\n"
                redirects_path.write_text(new_content)
            actions.append(f"Added {len(preview.redirects_needed)} redirect(s)")

        return actions

    def split_page(
        self,
        page_path: str,
        sections: list[str],
        output_dir: str | None = None,
    ) -> list[PageDraft]:
        """
        Split a large page into multiple smaller pages.

        Args:
            page_path: Path to the page to split
            sections: List of heading names to split at
            output_dir: Optional output directory for new pages

        Returns:
            List of PageDraft objects for the new pages
        """
        drafts: list[PageDraft] = []

        source_path = self.root_path / page_path
        if not source_path.exists():
            return drafts

        content = source_path.read_text()
        base_dir = output_dir or str(Path(page_path).parent)

        # Parse frontmatter
        frontmatter: dict[str, Any] = {}
        body = content
        if content.startswith("---"):
            try:
                import yaml

                parts = content.split("---", 2)
                if len(parts) >= 3:
                    frontmatter = yaml.safe_load(parts[1]) or {}
                    body = parts[2]
            except Exception as e:
                logger.debug(
                    "debug_migrator_frontmatter_parse_failed",
                    page=page_path,
                    error=str(e),
                    error_type=type(e).__name__,
                    action="using_raw_content",
                )

        # Split by headings
        # Find all h2 headings
        heading_pattern = re.compile(r"^##\s+(.+)$", re.MULTILINE)
        matches = list(heading_pattern.finditer(body))

        if not matches:
            # No headings to split on
            return drafts

        # Create index page with links to sections
        index_content = f"# {frontmatter.get('title', 'Index')}\n\n"
        index_content += "This section contains:\n\n"

        prev_end = 0
        intro_content = ""

        for i, match in enumerate(matches):
            heading = match.group(1)
            heading_slug = self._slugify(heading)

            # Check if this heading should be split
            if heading not in sections and heading_slug not in sections:
                continue

            # Get content before this heading (intro or previous section)
            if i == 0:
                intro_content = body[prev_end : match.start()].strip()

            # Get section content
            section_start = match.start()
            section_end = matches[i + 1].start() if i + 1 < len(matches) else len(body)
            section_content = body[section_start:section_end].strip()

            # Create draft for this section
            section_path = f"{base_dir}/{heading_slug}.md"
            section_fm = {
                "title": heading,
                "parent": page_path,
            }

            drafts.append(
                PageDraft(
                    path=section_path,
                    title=heading,
                    content=section_content,
                    frontmatter=section_fm,
                    source_pages=[page_path],
                )
            )

            # Add to index
            index_content += f"- [{heading}]({heading_slug})\n"

            prev_end = section_end

        # Create index draft
        if intro_content:
            index_content = intro_content + "\n\n" + index_content

        index_fm = frontmatter.copy()
        index_fm["layout"] = "section"

        drafts.insert(
            0,
            PageDraft(
                path=f"{base_dir}/_index.md",
                title=frontmatter.get("title", "Index"),
                content=index_content,
                frontmatter=index_fm,
                source_pages=[page_path],
            ),
        )

        return drafts

    def merge_pages(
        self,
        page_paths: list[str],
        output_path: str,
        title: str | None = None,
    ) -> PageDraft:
        """
        Merge multiple pages into one.

        Args:
            page_paths: Paths to pages to merge
            output_path: Output path for merged page
            title: Optional title for merged page

        Returns:
            PageDraft for the merged page
        """
        sections: list[str] = []
        all_frontmatter: dict[str, Any] = {}

        for page_path in page_paths:
            source_path = self.root_path / page_path
            if not source_path.exists():
                continue

            content = source_path.read_text()

            # Parse frontmatter
            body = content
            if content.startswith("---"):
                try:
                    import yaml

                    parts = content.split("---", 2)
                    if len(parts) >= 3:
                        fm = yaml.safe_load(parts[1]) or {}
                        body = parts[2]
                        # Merge frontmatter (first page wins for conflicts)
                        for key, value in fm.items():
                            if key not in all_frontmatter:
                                all_frontmatter[key] = value
                except Exception as e:
                    logger.debug(
                        "debug_migrator_merge_frontmatter_parse_failed",
                        page=page_path,
                        error=str(e),
                        error_type=type(e).__name__,
                        action="using_raw_content",
                    )

            # Add section heading and content
            page_title = all_frontmatter.get("title", Path(page_path).stem)
            sections.append(f"## {page_title}\n\n{body.strip()}")

        # Combine content
        merged_title = title or all_frontmatter.get("title", "Merged Document")
        merged_content = f"# {merged_title}\n\n" + "\n\n---\n\n".join(sections)

        all_frontmatter["title"] = merged_title

        return PageDraft(
            path=output_path,
            title=merged_title,
            content=merged_content,
            frontmatter=all_frontmatter,
            source_pages=page_paths,
        )

    def generate_redirects(
        self,
        moves: list[MoveOperation],
        output_format: str = "netlify",
    ) -> str:
        """
        Generate redirect rules for moved content.

        Args:
            moves: List of move operations
            output_format: Output format (netlify, nginx, apache)

        Returns:
            Redirect rules in requested format
        """
        redirects = [
            Redirect(
                from_path=self._path_to_url(move.source),
                to_path=self._path_to_url(move.destination),
            )
            for move in moves
        ]

        if output_format == "netlify":
            return "\n".join(r.to_netlify() for r in redirects)
        elif output_format == "nginx":
            return "\n".join(r.to_nginx() for r in redirects)
        elif output_format == "apache":
            return "\n".join(r.to_apache() for r in redirects)
        else:
            return "\n".join(str(r) for r in redirects)

    def _find_structure_issues(self) -> list[DebugFinding]:
        """Find potential structure issues in content."""
        findings: list[DebugFinding] = []

        if not self.site:
            return findings

        # Find orphan pages
        incoming_links: dict[str, int] = {}
        for page in self.site.pages:
            content = getattr(page, "content", "") or ""
            for match in re.finditer(r"\[([^\]]*)\]\(([^)]+)\)", content):
                target = match.group(2)
                if not target.startswith(("http://", "https://", "#")):
                    incoming_links[target] = incoming_links.get(target, 0) + 1

        orphans = []
        for page in self.site.pages:
            url = getattr(page, "href", "")
            if url and incoming_links.get(url, 0) == 0 and not self._is_in_navigation(page):
                orphans.append(str(getattr(page, "source_path", "")))

        if orphans:
            findings.append(
                DebugFinding(
                    title=f"{len(orphans)} orphan pages found",
                    description="Pages with no incoming links",
                    severity=Severity.WARNING,
                    category="structure",
                    metadata={"orphans": orphans[:10]},
                    suggestion="Add links to these pages or include in navigation",
                )
            )

        # Find very large pages
        large_pages = []
        for page in self.site.pages:
            content = getattr(page, "content", "") or ""
            line_count = content.count("\n")
            if line_count > 500:
                large_pages.append((str(getattr(page, "source_path", "")), line_count))

        if large_pages:
            findings.append(
                DebugFinding(
                    title=f"{len(large_pages)} large pages found (>500 lines)",
                    description="Consider splitting these into smaller pages",
                    severity=Severity.INFO,
                    category="structure",
                    metadata={"pages": large_pages[:10]},
                    suggestion="Use split_page() to break into sections",
                )
            )

        return findings

    def _is_in_navigation(self, page: Any) -> bool:
        """Check if page is in site navigation."""
        # Simplified check - would integrate with menu system
        url = getattr(page, "href", "")
        return url in ("/", "/index.html") or "index" in str(getattr(page, "source_path", ""))

    def _path_to_url(self, path: str) -> str:
        """Convert file path to URL."""
        # Remove content/ prefix if present
        if path.startswith("content/"):
            path = path[8:]

        # Remove .md extension
        if path.endswith(".md"):
            path = path[:-3]

        # Handle index files
        if path.endswith("/index") or path.endswith("/_index"):
            path = path.rsplit("/", 1)[0]

        return "/" + path.strip("/")

    def _links_match(self, link: str, target_url: str) -> bool:
        """Check if a link matches a target URL."""
        # Normalize both
        link_normalized = link.strip("/").rstrip("/")
        target_normalized = target_url.strip("/").rstrip("/")

        return link_normalized == target_normalized

    def _update_link(self, old_link: str, new_url: str) -> str:
        """Update a link to point to new location."""
        # Preserve any anchors or query params
        if "#" in old_link:
            anchor = old_link.split("#", 1)[1]
            return new_url + "#" + anchor
        return new_url

    def _update_file_link(self, link_update: LinkUpdate) -> None:
        """Update a link in a file."""
        file_path = Path(link_update.file_path)
        if not file_path.exists():
            return

        content = file_path.read_text()
        # Replace the specific link
        updated = content.replace(
            f"]({link_update.old_link})",
            f"]({link_update.new_link})",
        )
        file_path.write_text(updated)

    def _slugify(self, text: str) -> str:
        """Convert text to URL slug."""
        slug = text.lower()
        slug = re.sub(r"[^\w\s-]", "", slug)
        slug = re.sub(r"[\s_]+", "-", slug)
        return slug.strip("-")

    def _generate_recommendations(self, report: DebugReport) -> list[str]:
        """Generate recommendations based on analysis."""
        recommendations: list[str] = []

        for finding in report.findings:
            if finding.category == "structure":
                if "orphan" in finding.title.lower():
                    recommendations.append("Review orphan pages and add navigation")
                if "large" in finding.title.lower():
                    recommendations.append("Consider splitting large pages into sections")

        if not recommendations:
            recommendations.append("Content structure looks healthy! âœ…")

        return recommendations
